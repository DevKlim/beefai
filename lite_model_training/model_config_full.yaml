block_size: 256      # Max sequence length (context window)
n_layer: 6           # Number of Transformer layers 
n_head: 8            # Number of attention heads (n_embd must be divisible by n_head)
n_embd: 512          # Embedding dimension 

# Context ID vocabulary sizes (must match or exceed tokenizer's actual max IDs)
# These should be greater than or equal to the maximum segment/intra-line ID
# generated by the tokenizer for any song.
# scripts/05b_tokenize_data_full.py will print max observed values to help set these.
max_segment_types: 2048        # Max distinct segment types (e.g., bar_X_features, bar_X_flow_line_Y)
max_intra_line_positions: 96 # Max distinct positions within a segment component (e.g., SYLLABLES_COUNT, KICK_AT_0)
                             # Updated for stress: Line_start(1) + SylCount(1) + Offset(1) + Duration(1) + (MaxSyls(24) * (Start(1)+Dur(1)+Stress(1))) + EndSylSeq(1)
                             # = 1 + 1 + 1 + 1 + (24 * 3) + 1 = 4 + 72 + 1 = 77. 96 provides buffer.
                             # Max beat features: BarStart(1)+BPM(1)+TS(1) + (KICK_AT * 16) + END_KICK(1) + (SNARE_AT*16) + END_SNARE(1) + ... (4 instruments)
                             # = 1+1+1 + (16+1)*4 = 3 + 17*4 = 3 + 68 = 71.  96 is fine.

dropout: 0.1
bias: True           # True: bias in Linears and LayerNorms, False: no bias

# Training specific (can be overridden by train script arguments if implemented)
batch_size: 24       
learning_rate: 0.0003 
epochs: 30        
grad_accumulation_steps: 2 
                           
eval_interval_steps: 200 # How often to evaluate on validation set (in optimizer steps)
save_interval_steps: 500 # How often to save a checkpoint (in optimizer steps)
save_checkpoint_every_n_epochs: 5 # Save a checkpoint every N epochs, regardless of steps
                                   # Set to 0 or high value to disable epoch-based saving if step-based is preferred.

weight_decay: 0.01
seed: 153 # For reproducibility