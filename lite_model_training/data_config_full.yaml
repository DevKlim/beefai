# Configuration for data processing for the FULL model

# Paths for 05b_tokenize_data_full.py and scripts/train_flow_model.py
# These are relative to the project root.

# Path to the tokenizer configuration file (shared with lite model).
tokenizer_path: "beefai/flow_model/flow_tokenizer_config_v2.json"

# --- Inputs for 05b_tokenize_data_full.py ---
# Source of processed data from scripts/preprocess_dataset.py (shared with lite).
processed_data_source_dir: "data/processed_for_transformer/"

# --- Outputs for 05b_tokenize_data_full.py ---
# These .pt files will contain tokenized data ready for FlowDataset for the full model.
# These paths are also used as inputs by scripts/train_flow_model.py.
tokenized_data_output_dir: "data/tokenized_full/" # Base directory for full tokenized data
train_data_path: "data/tokenized_full/train_full.pt"
val_data_path: "data/tokenized_full/val_full.pt"

# --- Parameters for 05b_tokenize_data_full.py ---
max_songs_for_full: -1 # Number of songs to select. -1 means use all available songs.
val_split_ratio_for_full: 0.1 # Proportion of selected songs to use for validation (e.g., 10%)

# --- Checkpoint directory for scripts/train_flow_model.py ---
checkpoint_dir: "data/checkpoints/flow_model_full/"

# Audio processing parameters (reference, primarily used by feature extractors)
sample_rate: 44100
n_fft: 2048
hop_length: 512
win_length: 2048
n_mels: 128
fmin: 0
fmax: 16000